{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea984eda-a0f0-4755-852a-26a8607f9fdf",
   "metadata": {},
   "source": [
    "# Tensors , Basic Operations and Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02791d-9e1b-4f49-995b-7b1bae62b9f0",
   "metadata": {},
   "source": [
    "## Installing TensorFlow\n",
    "To install TensorFlow on your local machine you can use pip.\n",
    "```console\n",
    "pip install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e9393-b76a-4bb2-b791-e45a864ded3e",
   "metadata": {},
   "source": [
    "## Tensors \n",
    "A tensor is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe32489-0f65-4512-aa1c-b9e075e2de47",
   "metadata": {},
   "source": [
    "**Data Types Include**: float32, int32, string and others.\n",
    "\n",
    "**Shape**: Represents the dimension of data.\n",
    "\n",
    "Just like vectors and matrices tensors can have operations applied to them like addition, subtraction, dot product, cross product etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52c0ef-0f5c-4c0a-9bab-d8942246dcc8",
   "metadata": {},
   "source": [
    "### Scalar\n",
    "- A tensor with **zero dimensions**\n",
    "- Represents a single numerical value\n",
    "\n",
    "Example:  \n",
    "x = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a536c849-bd22-4593-a3f7-b9e118ba31ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "scalar = torch.tensor(5)\n",
    "scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a242a397-1a8f-4280-be10-759cf16e9408",
   "metadata": {},
   "source": [
    "### Vector\n",
    "- A tensor with **one dimension**\n",
    "- Represents a list of numbers\n",
    "\n",
    "Example:  \n",
    "x = [1, 2, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dce20c-4e09-4efb-b1b4-753323dfae4d",
   "metadata": {},
   "source": [
    "### Matrix\n",
    "- A tensor with **two dimensions**\n",
    "- Represents rows and columns\n",
    "\n",
    "Example:  \n",
    "x = [[1, 2],  \n",
    "     [3, 4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61f49dc-c230-49c4-8976-75ae82bf8cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565efc27-7d84-41db-b979-041158ed115a",
   "metadata": {},
   "source": [
    "### Higher-Order Tensors\n",
    "- Tensors with **three or more dimensions**\n",
    "- Used to represent images, videos, and batches of data\n",
    "\n",
    "Example:\n",
    "- 3D tensor → RGB image\n",
    "- 4D tensor → batch of images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c05a923-dc4a-4421-b2dc-7344fcf63305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3d = torch.randn(2, 3, 4)\n",
    "tensor_3d.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d46b05-edd5-4f46-8c82-4584f2af1b44",
   "metadata": {},
   "source": [
    "### 1. Creating a Tensor from Python Data\n",
    "\n",
    "Tensors can be created directly from Python lists or nested lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238b2484-7ce4-4211-9784-abfea34b9da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10),\n",
       " tensor([1, 2, 3, 4]),\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Scalar\n",
    "scalar = torch.tensor(10)\n",
    "\n",
    "# Vector\n",
    "vector = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Matrix\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "\n",
    "scalar, vector, matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1243f4-7d37-4950-b49a-a730bf7c2d8b",
   "metadata": {},
   "source": [
    "### 2. Creating Tensors with Specific Values\n",
    "\n",
    "Deep learning frameworks provide functions to create tensors filled with predefined values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b334ec-7c0f-4ae8-8029-743e5c3fd600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.]]),\n",
       " tensor([[1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor filled with zeros\n",
    "zeros_tensor = torch.zeros(2, 3)\n",
    "\n",
    "# Tensor filled with ones\n",
    "ones_tensor = torch.ones(2, 3)\n",
    "\n",
    "# Identity matrix\n",
    "identity_tensor = torch.eye(3)\n",
    "\n",
    "zeros_tensor, ones_tensor, identity_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9d6f5-2253-47d1-b56f-5d0e1853075c",
   "metadata": {},
   "source": [
    "### 3. Creating Random Tensors\n",
    "\n",
    "Random tensors are widely used to initialize weights in neural networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a130067-fbe7-4bfe-a478-39f392a7d2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9042, 0.0924, 0.8552],\n",
       "         [0.7995, 0.1496, 0.0989]]),\n",
       " tensor([[-0.6224, -0.5790,  1.2360],\n",
       "         [ 1.8613,  0.0829, -1.0737]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random values between 0 and 1\n",
    "random_uniform = torch.rand(2, 3)\n",
    "\n",
    "# Random values from normal distribution (mean=0, std=1)\n",
    "random_normal = torch.randn(2, 3)\n",
    "\n",
    "random_uniform, random_normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da04ba0-34bf-4c91-82ea-b2e119bb59f1",
   "metadata": {},
   "source": [
    "### 4. Creating Tensors with a Specific Data Type\n",
    "\n",
    "Tensors can be created with specific data types such as integers or floating-point values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abeb5807-9bd0-4a05-a038-4ef8dd0e9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "int_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "\n",
    "float_tensor.dtype, int_tensor.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e466e-3d76-4df8-8922-92c348d0d322",
   "metadata": {},
   "source": [
    "### 5. Creating Tensors with a Specific Shape\n",
    "\n",
    "Sometimes we need tensors of a particular shape for neural network layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df1efb5-6463-4ab1-b3f3-d4564eadc9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty tensor (values are uninitialized)\n",
    "empty_tensor = torch.empty(3, 2)\n",
    "\n",
    "# Create a tensor with the same shape as another tensor\n",
    "reference = torch.ones(2, 2)\n",
    "same_shape = torch.zeros_like(reference)\n",
    "\n",
    "empty_tensor, same_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f2c76c-b12f-4d8a-a584-ce37e771627f",
   "metadata": {},
   "source": [
    "### 6. Creating Tensors Using Ranges\n",
    "\n",
    "Range-based tensors are useful for indexing and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f6ee42-3a7c-405b-82a1-4948a04aec1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence of numbers\n",
    "range_tensor = torch.arange(0, 10)\n",
    "\n",
    "# Evenly spaced values\n",
    "linspace_tensor = torch.linspace(0, 1, steps=5)\n",
    "\n",
    "range_tensor, linspace_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c67fa-27fe-4860-9d19-82d452e69c0c",
   "metadata": {},
   "source": [
    "### 7. Creating Tensors That Track Gradients\n",
    "\n",
    "For training neural networks, tensors must track gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63db2bec-d35b-44bf-8c8a-789770138c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c917351e-8a03-4658-a7af-ad7f84340a75",
   "metadata": {},
   "source": [
    "## Key Points to Remember\n",
    "\n",
    "- Tensors can be created from lists, predefined values, or random distributions\n",
    "- Shape, data type, and device are important properties\n",
    "- Random tensors are commonly used for weight initialization\n",
    "- Gradient tracking is essential for training neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff3724-bb61-4fe6-8178-6fb9b344b8a3",
   "metadata": {},
   "source": [
    "## Indexing and Slicing of Tensors\n",
    "\n",
    "Indexing and slicing are used to access or extract specific elements or parts of a tensor.  \n",
    "This is very important in deep learning for selecting features, batches, channels, and regions of data.\n",
    "\n",
    "### What is Indexing?\n",
    "\n",
    "Indexing means selecting **individual elements** of a tensor using their position (index).  \n",
    "Indexing in tensors starts from **0**.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d11c8028-4dba-45cc-858f-8ce275c1925c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 1D tensor (vector)\n",
    "x = torch.tensor([10, 20, 30, 40, 50])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f38dd-8ae7-4515-9739-34be1c37e20d",
   "metadata": {},
   "source": [
    "### 1. Indexing a 1D Tensor (Vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "418f4fbf-46d7-4fe6-8f58-361200826b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]   # first element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17917afa-2fa4-4330-b22d-201a35d3a318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]   # third element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c03eecf8-d246-4679-916e-9d42b694d229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1]  # last element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b42a1-6234-4a39-af5d-e5cb6adc8d57",
   "metadata": {},
   "source": [
    "- Positive index → counts from the beginning  \n",
    "- Negative index → counts from the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadb232-a5b6-4a8f-b861-8879631f808c",
   "metadata": {},
   "source": [
    "### 2. Slicing a 1D Tensor\n",
    "\n",
    "Slicing extracts a **range of elements** from a tensor.\n",
    "Syntax: `start : end` (end index is excluded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7896f02d-2104-474c-9dd5-1cfa008f1b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 30, 40])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:4]   # elements from index 1 to 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a493d184-5dab-4115-8dc9-620ed95b5c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:3]    # first three elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "958e1968-6f1c-4b7f-a5fc-5161b92363fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 40, 50])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:]    # elements from index 2 to end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d9528-247f-4142-8b3c-94e4cd353559",
   "metadata": {},
   "source": [
    "### Step Size in Slicing\n",
    "\n",
    "Syntax: `start : end : step`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe2086fa-e600-4c74-880a-c8c75441cc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 30, 50])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[::2]   # every second element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aed8db50-5a37-46f4-8b56-b203d22b1881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50, 40, 30, 20, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([10, 20, 30, 40, 50])\n",
    "torch.flip(x, dims=[0])\n",
    " # reverse the tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac5591-0f7f-4b2c-a827-5a2642333a3a",
   "metadata": {},
   "source": [
    "### 3. Indexing a 2D Tensor (Matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "754e6c14-3c9a-4168-91fa-ab4193417f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D tensor\n",
    "m = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a71770c-9da6-4feb-8e3e-f1f9aa828e72",
   "metadata": {},
   "source": [
    "### Accessing Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f4fd260-35a6-4c03-bafa-c3aa7307575d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]     # first row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beb64018-db30-4e37-89b6-e2095acba837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[1]     # second row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edba33b8-335e-4b92-ad21-da17926b6845",
   "metadata": {},
   "source": [
    "### Accessing Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c143ec-c2d8-4afe-96b6-34137d320112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:, 0]  # first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47b6de3b-8d36-4b13-864d-8244434497a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:, 2]  # third column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be523d3-54c4-4c0c-b922-6ce51d162cf4",
   "metadata": {},
   "source": [
    "### 3. Slicing a 2D Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a67f7d87-ee8e-414c-bf2d-f9b83c12dda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0:2, 1:3]  # rows 0–1 and columns 1–2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "391acc65-edcb-4a3d-922a-d26a3c308e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:, 1:]     # all rows, columns from index 1 onward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae6320f5-feb7-469a-82e2-a802c6df6472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:, 1:]     # all rows, columns from index 1 onward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fcdabe-d541-4fcc-bd65-efb7b079e06f",
   "metadata": {},
   "source": [
    "### 4. Indexing Higher-Dimensional Tensors\n",
    "\n",
    "Higher-order tensors are common in deep learning.\n",
    "Example: 3D tensor (batch, rows, columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27f55752-f247-4a34-8e01-912c1232752c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2, 3, 4)\n",
    "t.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bf5640-b42d-4bdd-9b26-f691d5a85171",
   "metadata": {},
   "source": [
    "### 5. Using Ellipsis (...)\n",
    "\n",
    "Ellipsis is used to represent missing dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b2591e9-900b-465a-a740-2bf500844bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3199,  0.2449,  0.2132],\n",
       "        [-2.2484,  0.3037, -0.0742]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1]   # all elements from last dimension index 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d2d248-ac6f-4276-b7f4-80d987bb65f6",
   "metadata": {},
   "source": [
    "### 6. Boolean Indexing\n",
    "\n",
    "Boolean indexing selects elements based on conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74dc9184-7898-4809-85d1-ffce0795e547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 20])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5, 10, 15, 20])\n",
    "x[x > 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ffe23-2198-4d71-ba0d-f465e8ae92b2",
   "metadata": {},
   "source": [
    "## Reshaping Tensors\n",
    "\n",
    "Reshaping means changing the **shape (dimensions)** of a tensor **without changing its data**.  \n",
    "In deep learning, reshaping is very common when preparing data for neural network layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d7482b-07fa-4343-b53e-84ea48649265",
   "metadata": {},
   "source": [
    "### Why Reshaping is Needed in Deep Learning\n",
    "\n",
    "- Neural network layers expect inputs in specific shapes  \n",
    "- Images, text, and batches must be reshaped correctly  \n",
    "- Helps convert data between layers (e.g., CNN → Fully Connected layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828bcf91-1bef-4252-b871-9be3b3a56e8c",
   "metadata": {},
   "source": [
    "### Understanding Tensor Shape\n",
    "\n",
    "The **shape** of a tensor tells:\n",
    "- How many dimensions it has  \n",
    "- How many elements are in each dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "539232cc-5157-440d-9be3-1ef40857c640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0801c2-c771-45e2-a3ec-28d38bfa5245",
   "metadata": {},
   "source": [
    "### 1. Reshaping Using `reshape()`\n",
    "\n",
    "The `reshape()` function changes the shape of a tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd1ca4fc-d36a-4645-99e3-133e691236ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "x_reshaped = x.reshape(2, 3)\n",
    "x_reshaped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e19e20c-5066-4952-b027-b44a46f2bf04",
   "metadata": {},
   "source": [
    "Rule:  \n",
    "Total number of elements **must remain the same**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a89d87-2667-42c3-9bd0-d6546f8ff839",
   "metadata": {},
   "source": [
    "### 2. Using `-1` to Automatically Infer Size\n",
    "\n",
    "PyTorch can automatically calculate one dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8eb4209-1310-4a70-8793-ba3c841118da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d95243-f0a1-4bfd-8c4f-5d0d439855f8",
   "metadata": {},
   "source": [
    "Here, PyTorch finds the correct value for `-1`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d41e8-4f78-44b2-8071-9875d390871b",
   "metadata": {},
   "source": [
    "### 3. Flattening a Tensor\n",
    "\n",
    "Flattening means converting a multi-dimensional tensor into a 1D tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5791da29-325a-428a-9b92-7bfcb8db00fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "m.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b7b5da-232b-4cbc-8b98-59eb67f84646",
   "metadata": {},
   "source": [
    "### 4. `view()` vs `reshape()`\n",
    "\n",
    "Both change the shape of a tensor, but they differ internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e324dbc-84a0-44f6-bce6-ebca37a38833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "x.view(2, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f490b-c919-4bd7-831c-23e7eb8a7032",
   "metadata": {},
   "source": [
    "- `view()` works only if tensor memory is contiguous  \n",
    "- `reshape()` is safer and preferred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a087d24-c3b0-4e9f-9a88-260f60017471",
   "metadata": {},
   "source": [
    "### 5. Adding or Removing Dimensions\n",
    "\n",
    "Sometimes we need to add or remove dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "242a56b5-e13a-4595-9698-f426a1cbd464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Add a new dimension\n",
    "x.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70f1f0ec-a2de-4500-8056-020cd629a060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dimensions of size 1\n",
    "x.unsqueeze(0).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f520e5-325f-41df-bb87-f9c9c1f6b262",
   "metadata": {},
   "source": [
    "## Tensor Arithmetic Operations\n",
    "\n",
    "Tensor arithmetic operations are mathematical operations performed on tensors.  \n",
    "These operations are applied **element-wise** and are heavily used in deep learning for computing outputs, losses, and gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f82b90d6-cb8b-4449-b9ce-9c0cb4e0dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e3e50a1-6af6-4374-89f2-f4f5d1c50c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 7, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addition\n",
    "a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc9504b7-8a92-436b-a717-ec36e12d8caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3, -3, -3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtraction\n",
    "a - b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66fdc5cc-f9d9-4ca4-967b-928dc01b2a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 10, 18])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplication (element-wise)\n",
    "a * b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37d24e6b-b195-4e30-b364-f13f2d97354c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.4000, 0.5000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Division\n",
    "a / b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0634fc-de18-4def-ab77-895e98c2c79f",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8e1e40e-b989-4466-ad1b-a6fc573d3d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.tensor([[1, 2],\n",
    "                   [3, 4]])\n",
    "m2 = torch.tensor([[5, 6],\n",
    "                   [7, 8]])\n",
    "\n",
    "torch.matmul(m1, m2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59bd6f-1d21-4020-aa82-9f93b7df67dd",
   "metadata": {},
   "source": [
    "## Broadcasting \n",
    "\n",
    "Broadcasting allows arithmetic operations between tensors of **different shapes**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205aa1b0-43f3-4318-a989-72e4714e487b",
   "metadata": {},
   "source": [
    "### Rules of Broadcasting\n",
    "1. Compare tensor shapes from right to left  \n",
    "2. Dimensions are compatible if they are equal or one of them is 1  \n",
    "3. Smaller tensor is automatically expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99f4ed39-0392-4bee-81a7-3a644cd944a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4, 6],\n",
       "        [5, 7, 9]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "y = torch.tensor([1, 2, 3])\n",
    "\n",
    "x + y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a709c24-aab4-491a-9150-9f034216ba41",
   "metadata": {},
   "source": [
    "Here, `y` is broadcast across rows of `x`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959dd19-5f4f-4f02-9adc-75234051a736",
   "metadata": {},
   "source": [
    "Broadcasting avoids copying data and improves performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67962e1d-816e-4728-b273-1fbae9492f94",
   "metadata": {},
   "source": [
    "## Need for Non-Linear Activation Functions\n",
    "\n",
    "Without non-linear activation functions:\n",
    "- Neural networks become linear models\n",
    "- Stacking layers has no added benefit\n",
    "- Complex patterns cannot be learned\n",
    "\n",
    "Activation functions introduce **non-linearity**, enabling deep networks to learn complex relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e773009-2083-404a-8f5f-869c8fef8b8a",
   "metadata": {},
   "source": [
    "## Sigmoid Activation Function\n",
    "\n",
    "The sigmoid activation function maps input values to the range (0, 1).\n",
    "\n",
    "Formula:\n",
    "σ(x) = 1 / (1 + e⁻ˣ)\n",
    "\n",
    "Uses:\n",
    "- Binary classification\n",
    "- Output layer for probability prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3454426-f45a-45f6-b487-9a3be44b9daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0474, 0.2689, 0.5000, 0.7311, 0.9526])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.tensor([-3.0, -1.0, 0.0, 1.0, 3.0])\n",
    "F.sigmoid(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65174208-0f76-4516-b4c6-40f2d5bd2286",
   "metadata": {},
   "source": [
    "## Sigmoid Activation Function\n",
    "\n",
    "![Sigmoid Activation Function](https://media.geeksforgeeks.org/wp-content/uploads/20241029120537926197/Sigmoid-Activation-Function.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a221e-eacc-4f97-9d83-2c5dee9fc3a1",
   "metadata": {},
   "source": [
    "### Properties of Sigmoid\n",
    "- Output range: (0, 1)\n",
    "- Smooth and differentiable\n",
    "- Can cause vanishing gradient for large values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc40ebf-ae10-4fdc-82f6-2069ae6a7b6a",
   "metadata": {},
   "source": [
    "## 2. Hyperbolic Tangent (tanh) Activation Function\n",
    "\n",
    "\n",
    "\n",
    "The **tanh** function maps input values to the range **(-1, 1)**.  \n",
    "It is zero-centered, which often leads to faster convergence than Sigmoid for hidden layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b9cfb-d420-4503-a3db-f59f1a7e0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate input values\n",
    "x = torch.linspace(-10, 10, 100)\n",
    "\n",
    "# Apply tanh activation\n",
    "y_tanh = torch.tanh(x)\n",
    "\n",
    "# Plot the tanh function\n",
    "plt.plot(x.numpy(), y_tanh.numpy())\n",
    "plt.title(\"tanh Activation Function (Code Plot)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"tanh(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ae590-a3ae-4b3b-8c7e-eec9be89a1b2",
   "metadata": {},
   "source": [
    "![tanh Activation Function](https://media.geeksforgeeks.org/wp-content/uploads/20241029120618881107/Tanh-Activation-Function.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1162683d-76c3-4c3c-94e1-1c058785715a",
   "metadata": {},
   "source": [
    "## 3. Rectified Linear Unit (ReLU)\n",
    "\n",
    "![ReLU Activation Function](https://media.geeksforgeeks.org/wp-content/uploads/20241029120652402777/relu-activation-function.png)\n",
    "\n",
    "ReLU is the most popular activation function in deep learning.  \n",
    "It outputs zero for negative values and the input for positive values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e70ee80-4bf3-4a52-b827-01be97f797c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate input values\n",
    "x = torch.linspace(-10, 10, 100)\n",
    "\n",
    "# Apply ReLU activation\n",
    "y_relu = F.relu(x)\n",
    "\n",
    "# Plot the ReLU function\n",
    "plt.plot(x.numpy(), y_relu.numpy())\n",
    "plt.title(\"ReLU Activation Function (Code Plot)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ReLU(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6551e04-9666-4ac4-b314-8aab13411ad2",
   "metadata": {},
   "source": [
    "## 4. Softmax Function (Multi-class Classification)\n",
    "\n",
    "![Softmax Function](https://media.geeksforgeeks.org/wp-content/uploads/20241029120724445438/softmax.png)\n",
    "\n",
    "Softmax converts raw scores (logits) into **probabilities** that sum to 1.  \n",
    "It is used in the **output layer for multi-class classification**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02de2169-7024-4917-bc0d-86ab3e47c914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6590, 0.2424, 0.0986])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "scores = torch.tensor([2.0, 1.0, 0.1])\n",
    "\n",
    "# Apply Softmax\n",
    "y_softmax = F.softmax(scores, dim=0)\n",
    "\n",
    "y_softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb600fcd-13ed-4411-be17-85a2b52e5981",
   "metadata": {},
   "source": [
    "The output shows the **probabilities** of each class.  \n",
    "Softmax is ideal for problems with >2 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf61ca0a-a210-43cb-8868-e5d22fcc59bb",
   "metadata": {},
   "source": [
    "# Summary of Activation Functions\n",
    "\n",
    "| Activation | Output Range | Why Used |\n",
    "|------------|--------------|-----------|\n",
    "| Sigmoid    | (0, 1)       | Binary classification, probability output |\n",
    "| tanh       | (-1, 1)      | Hidden layers, zero-centered |\n",
    "| ReLU       | [0, ∞)       | Deep models, fast convergence |\n",
    "| Softmax    | (0, 1)       | Multi-class classification |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c7cb5-8f71-48e8-8114-460cb072cb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
