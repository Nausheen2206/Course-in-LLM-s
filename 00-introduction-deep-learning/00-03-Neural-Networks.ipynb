{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbc3e27",
   "metadata": {},
   "source": [
    "\n",
    "# Neural Networks: Fundamental Concepts\n",
    "\n",
    "This chapter introduces the fundamental concepts required to understand\n",
    "how neural networks process information and make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e91c65",
   "metadata": {},
   "source": [
    "\n",
    "## Biological Inspiration of Neural Networks\n",
    "\n",
    "Neural networks are inspired by the structure and functioning of the human brain.\n",
    "The brain consists of billions of interconnected neurons that communicate using electrical signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb389d",
   "metadata": {},
   "source": [
    "\n",
    "### Key Components of a Biological Neuron\n",
    "\n",
    "- **Dendrites**: receive signals from other neurons  \n",
    "- **Cell body (soma)**: processes incoming signals  \n",
    "- **Axon**: transmits signals to other neurons  \n",
    "\n",
    "Learning occurs by strengthening or weakening synaptic connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c5c88",
   "metadata": {},
   "source": [
    "\n",
    "## Artificial Neuron Model\n",
    "\n",
    "An artificial neuron is a mathematical model designed to mimic\n",
    "the behavior of a biological neuron.\n",
    "\n",
    "\n",
    "## What is a neuron?\n",
    "\n",
    "An artificial neuron (also referred to as a perceptron) is a mathematical function.  \n",
    "It takes one or more inputs that are multiplied by values called **weights** and added together.  \n",
    "This value is then passed to a non-linear function, known as an **activation function**,  \n",
    "to become the neuron’s output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac414e1",
   "metadata": {},
   "source": [
    "\n",
    "### Core Elements of an Artificial Neuron\n",
    "\n",
    "- Inputs represent features  \n",
    "- Weights represent importance of features  \n",
    "- Bias shifts the activation threshold  \n",
    "- Output represents the neuron response  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ff4f7",
   "metadata": {},
   "source": [
    "\n",
    "## Structure of an Artificial Neuron\n",
    "\n",
    "An artificial neuron computes its output in two stages:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cace9b",
   "metadata": {},
   "source": [
    "\n",
    "- **Linear combination** of inputs  \n",
    "- **Non-linear activation** of the result  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fae5d3",
   "metadata": {},
   "source": [
    "\n",
    "The computation can be written as:\n",
    "\n",
    "z = w₁x₁ + w₂x₂ + … + wₙxₙ + b  \n",
    "a = f(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304eb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1.0, 2.0, 3.0])\n",
    "w = np.array([0.3, 0.5, -0.2])\n",
    "b = 0.4\n",
    "\n",
    "z = np.dot(w, x) + b\n",
    "z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13994dc5",
   "metadata": {},
   "source": [
    "\n",
    "## Weights and Bias: Role and Significance\n",
    "\n",
    "Weights and bias are trainable parameters that control neuron behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f14714",
   "metadata": {},
   "source": [
    "\n",
    "### Weights\n",
    "\n",
    "- Control contribution of each input  \n",
    "- Learned during training  \n",
    "- Determine feature importance  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a352d7",
   "metadata": {},
   "source": [
    "\n",
    "### Bias\n",
    "\n",
    "- Allows activation even when inputs are zero  \n",
    "- Shifts decision boundary  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75417237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.array([2.0, 3.0])\n",
    "w = np.array([0.5, 0.5])\n",
    "\n",
    "np.dot(w, x), np.dot(w, x) + 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01374e96",
   "metadata": {},
   "source": [
    "\n",
    "## Activation Functions and Non-Linearity\n",
    "\n",
    "Activation functions introduce non-linearity into neural networks.\n",
    "Without them, networks behave like linear models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8b706",
   "metadata": {},
   "source": [
    "\n",
    "### Common Activation Functions\n",
    "\n",
    "- Step function  \n",
    "- Sigmoid  \n",
    "- Tanh  \n",
    "- ReLU  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb02cc",
   "metadata": {},
   "source": [
    "\n",
    "Non-linearity allows neural networks to learn complex patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = np.array([-2, -1, 0, 1, 2])\n",
    "relu = np.maximum(0, z)\n",
    "relu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed1b4d",
   "metadata": {},
   "source": [
    "\n",
    "## Single Neuron Model (Perceptron)\n",
    "\n",
    "The perceptron is the simplest form of a neural network.\n",
    "It is mainly used for binary classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e8c8c",
   "metadata": {},
   "source": [
    "\n",
    "### Perceptron Decision Rule\n",
    "\n",
    "- Output = 1 if (w·x + b) ≥ 0  \n",
    "- Output = 0 otherwise  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9b633",
   "metadata": {},
   "source": [
    "\n",
    "### Limitation of Perceptron\n",
    "\n",
    "The perceptron can only solve linearly separable problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0014d3",
   "metadata": {},
   "source": [
    "\n",
    "## Linear Transformation in Neural Networks (Wx + b)\n",
    "\n",
    "Neural networks use matrix operations to compute outputs efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2735d1",
   "metadata": {},
   "source": [
    "\n",
    "The linear transformation is expressed as:\n",
    "\n",
    "z = Wx + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array([[1, 2], [3, 4]])\n",
    "W = np.array([[0.2, 0.4], [0.6, 0.8]])\n",
    "b = np.array([0.1, 0.2])\n",
    "\n",
    "np.dot(X, W) + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77baa8",
   "metadata": {},
   "source": [
    "\n",
    "## From Single Neuron to Fully Connected Layer\n",
    "\n",
    "A fully connected layer consists of multiple neurons working in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c8b19",
   "metadata": {},
   "source": [
    "\n",
    "- Each neuron has its own weights and bias  \n",
    "- All neurons receive the same input  \n",
    "- Enables learning multiple features  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f5554",
   "metadata": {},
   "source": [
    "\n",
    "## Layers in a Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347d322",
   "metadata": {},
   "source": [
    "\n",
    "### Input Layer\n",
    "\n",
    "- Receives raw input features  \n",
    "- No trainable parameters  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef64666",
   "metadata": {},
   "source": [
    "\n",
    "### Hidden Layer\n",
    "\n",
    "- Performs intermediate computations  \n",
    "- Learns feature representations  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc56b0",
   "metadata": {},
   "source": [
    "\n",
    "### Output Layer\n",
    "\n",
    "- Produces final prediction  \n",
    "- Depends on the task type\n",
    "\n",
    "![Artificial Neuron Diagram](https://miro.medium.com/v2/resize:fit:750/format:webp/1*ToPT8jnb5mtnikmiB42hpQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a623d",
   "metadata": {},
   "source": [
    "\n",
    "## Forward Pass: Flow of Information Through the Network\n",
    "\n",
    "The forward pass describes how data flows through the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70497da7",
   "metadata": {},
   "source": [
    "\n",
    "### Steps in the Forward Pass\n",
    "\n",
    "1. Input enters the network  \n",
    "2. Linear transformation is applied  \n",
    "3. Activation function is applied  \n",
    "4. Output is produced  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c4e7f5",
   "metadata": {},
   "source": [
    "\n",
    "The forward pass is used during both training and inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd17f82",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "1. Compute neuron output for different weights and bias  \n",
    "2. Compare ReLU and Sigmoid activation functions  \n",
    "3. Explain why non-linearity is necessary  \n",
    "4. Identify limitations of a single neuron  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
